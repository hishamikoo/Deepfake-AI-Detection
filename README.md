# ğŸ†ğŸ™ï¸ WaveTruth: AI-Generated Voice Detection & Gender Classification  

ğŸ“„ [**Full Detailed Research Report (PDF)**](https://github.com/hishamikoo/Deepfake-AI-Detection/blob/main/Research%20Paper%20-%20WaveTruth.pdf)  

ğŸ“ŠğŸ§ The raw audio clips dataset used for this project is available on [**Google Drive**](https://drive.google.com/drive/u/0/folders/1joD1gSSAzIXuPOoOuYL1Tn-WiEehtvMY).  

ğŸ“Š The feature-extracted dataset in Excel format is available in the [**audio_dataset folder**](./dataset/) under the main branch.  

---

## ğŸ“Œ Overview  
The rapid advancement of artificial intelligence in speech synthesis has led to an increase in AI-generated voices that closely mimic human speech. **WaveTruth** is a deep learning-based system designed to:  
- ğŸ­ **Detect AI-generated voices** vs. **real human voices**  
- ğŸš» **Classify gender** (male/female) of both AI-generated and real voices  
- ğŸŒ Provide an **interactive web application** for real-time voice detection  

This project uses **Transfer Learning with Feedforward Neural Networks (FFNN)** to achieve state-of-the-art accuracy in deepfake speech detection.  

<p align="center">
  <img src="Images/Pipeline.png" alt="Pipeline" />
</p>

---

## ğŸ”¥ Project Features  
âœ… **Custom Dataset**: 1,956 audio clips (~2.7 hours) covering real and AI-generated voices from diverse accents (Canadian, Australian, Indian, American, English, European, and African).  
âœ… **Deep Learning Models**: Comparison of 16 machine learning and deep learning models, with FFNN outperforming traditional models.  
âœ… **Web App Deployment**: A Django-based application providing real-time audio classification.  
âœ… **Feature Extraction**: Utilizes spectral, energy, pitch, and temporal features for robust speech analysis.  

### ğŸ“Œ Practical Applications  
- âœ… Fake audio detection in journalism & social media.  
- âœ… Deepfake threat detection in security.  
- âœ… AI-generated content filtering.  
- âœ… Voice biometrics & authentication.  

<p align="center">
  <img src="Images/model%20visualization.png" alt="Model Visualization" />
</p>

---

## ğŸ“Š Dataset & Processing  
1. **Data Collection**: Real voices sourced from podcasts, speeches, and lectures; AI voices generated using various TTS models.  
2. **Preprocessing**:  
   - ğŸµ Audio split into 5-second clips.  
   - ğŸ›ï¸ Normalization to a fixed decibel level.  
   - ğŸ“Š Feature extraction: Spectral centroid, bandwidth, contrast, pitch mean, Mel spectrogram, speech rate, and more.
   - MinMax Scaling of Extracted Features.
   - Principal Compnent Analyisis.

<p align="center">
  <img src="Images/Correlation-Matrix.png" alt="Correlation Matrix" />
</p>

---

## ğŸ¯ Results & Key Findings  
- ğŸš¨ Traditional models like **kNN and NaÃ¯ve Bayes** struggled with complex audio features.  
- ğŸŒ³ **Tree-based models (Random Forest, XGBoost, CatBoost)** performed significantly better (75%-90% accuracy).  
- ğŸ¤– **Deep learning models (FFNN, RNN)** outperformed traditional methods, with **Transfer Learning FFNN achieving the maximum generalization**.  
- ğŸš» Gender classification was successfully integrated, improving the model's practical applications.  

<p align="center">
  <img src="Images/Model-performances.png" alt="Model Performance" />
</p>

---

## ğŸ” Model Selection & Performance  
A comparative analysis of machine learning and deep learning models was conducted:  

ğŸ“Œ **Traditional Models**: kNN, NaÃ¯ve Bayes, Decision Trees, Logistic Regression, SVM, Random Forest, XGBoost, CatBoost, etc.  
ğŸ“Œ **Deep Learning Models**: Feedforward Neural Networks (FFNN), Recurrent Neural Networks (RNN), Transfer Learning-based FFNN.  
ğŸ“Œ **Selected Model**: **Transfer Learning Based Deep Learning models** outperformed all others in terms of generalization, achieving **90%+ accuracy** in distinguishing AI-generated vs. real voices.  

---

## ğŸŒ Web Application  
WaveTruth is deployed as a **Django-based web application**, allowing users to:  
ğŸµ Upload an audio file.  
ğŸ§  Get real-time predictions on whether the voice is AI-generated or real.  
ğŸš» Determine the gender of the speaker.  

---

## ğŸš€ Installation & Usage  
### ğŸ“Œ Prerequisites  
- Python 3.8+  
- TensorFlow  
- Django  
- Librosa (for audio processing)  
- NumPy, Pandas, Matplotlib & Seaborn (for analysis)  
- scikit-learn  
- LabelEncoder and OneHotEncoder (for categorical feature encoding)  
- Dense, Dropout, BatchNormalization, and Activation layers  
- Optimizers - Adam, SGD, RMSprop, Adagrad  
- Sequential and Functional API models  

---

## ğŸ”® Future Improvements  
ğŸ”¹ Expand dataset with more diverse voices and languages.  
ğŸ”¹ Enhance real-time processing for faster classification.  
ğŸ”¹ Optimize the model for mobile and embedded systems.  

---

## ğŸ¤ Contributing  
Pull requests and feature suggestions are welcome! Feel free to open an issue or contribute to improving **WaveTruth**.  

---

## ğŸ“œ License  
This project is licensed under the MIT License. See `LICENSE` for details.  

---

## ğŸ“§ Contact  
For questions or collaborations, contact **Hisham Iqbal Khokhar** at **hishamjavaid2@gmail.com**.  
