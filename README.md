# Deepfake-AI-Detection

In recent years, AI-generated voices have become increasingly sophisticated, particularly in applications such as virtual assistants, media production, and customer service automation. These AI voices are often generated using deep learning models, making it difficult to distinguish them from real human speech. This presents challenges in fields such as security, fraud detection, and content moderation. 

Motivated by these challenges, this project aims to develop a machine learning model capable of detecting AI-generated voices and differentiating them from human speech.

The aim of this project is to develop a machine learning model capable of accurately detecting deepfake audio by analyzing and distinguishing between real and AI-generated audio clips. 

Using a dataset of over 2,100 audio samples, the model is trained on various audio features, including file size, spectral centroid mean, spectral bandwidth mean, RMS mean, zero-crossing rate mean, spectral contrast mean, pitch mean, pitch confidence mean, mel spectrogram mean, mel spectrogram variance, energy mean, and speech rate, to identify patterns and markers indicative of deepfake audio.
